{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo #\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running for the first time, install dependencies on your virtual environment (initially install ipykernel to your environment first)\n",
    "# %pip install -r libs/requirements.txt\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "%run -i libs/dependencies.py\n",
    "\n",
    "\n",
    "### Sample References\n",
    "\"\"\"\n",
    "    #1 metal\n",
    "    # input_path = \"training_body_metalart_img12224_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img12224_512x512x1.raw\"\n",
    "    # input_path = \"training_body_metalart_img70_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img70_512x512x1.raw\"\n",
    "    # input_path = \"training_body_metalart_img93_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img93_512x512x1.raw\"\n",
    "    # input_path = \"training_body_metalart_img11222_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img11222_512x512x1.raw\"\n",
    "\n",
    "    # 2 metal\n",
    "    # input_path = \"training_body_metalart_img118_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img118_512x512x1.raw\"\n",
    "    # input_path = \"training_body_metalart_img259_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img259_512x512x1.raw\"\n",
    "    # input_path = \"training_body_metalart_img11158_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img11158_512x512x1.raw\"\n",
    "\n",
    "    # 2+ metal\n",
    "    # input_path = \"training_body_metalart_img17_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img17_512x512x1.raw\"\n",
    "    # input_path = \"training_body_metalart_img1013_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img1013_512x512x1.raw\"\n",
    "    # input_path = \"training_body_metalart_img6615_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img6615_512x512x1.raw\"\n",
    "    # input_path = \"training_body_metalart_img3064_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img3064_512x512x1.raw\"\n",
    "    # input_path = \"training_body_metalart_img11008_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img11008_512x512x1.raw\"\n",
    "    # input_path = \"training_body_metalart_img11085_512x512x1.raw\"\n",
    "    # clean_path = \"training_body_nometal_img11085_512x512x1.raw\"\n",
    "    # input_path = \"unseen\\\\training_body_metalart_img4843_512x512x1.raw\"\n",
    "    # clean_path = \"unseen\\\\training_body_nometal_img4843_512x512x1.raw\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inputs Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Inputs Cell\n",
    "\"\"\"\n",
    "    Regular inputs:\n",
    "    lr = 10\n",
    "    num_iters = 200\n",
    "\"\"\"\n",
    "\n",
    "### Dependencies\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def inputs():\n",
    "\n",
    "    # Widgets\n",
    "    lr_input = widgets.FloatText(\n",
    "        value=10.0,\n",
    "        description='Learning Rate Input:',\n",
    "        step=0.1,\n",
    "        layout=widgets.Layout(width='500px'),\n",
    "        style={'description_width': '200px'}\n",
    "    )\n",
    "    iter_input = widgets.IntText(\n",
    "        value=200,\n",
    "        description='Number of Iterations Input:',\n",
    "        step=5,\n",
    "        layout=widgets.Layout(width='500px'),\n",
    "        style={'description_width': '200px'}\n",
    "    )\n",
    "    artifact_path_input = widgets.Text(\n",
    "        description='Artifact File Path:',\n",
    "        placeholder='File Path Here...',\n",
    "        layout=widgets.Layout(width='500px'),\n",
    "        style={'description_width': '200px'}\n",
    "    )\n",
    "    clean_path_input = widgets.Text(\n",
    "        description='Clean File Path:',\n",
    "        placeholder='File Path Here...',\n",
    "        layout=widgets.Layout(width='500px'),\n",
    "        style={'description_width': '200px'}\n",
    "    )\n",
    "    anatomy_input = widgets.Text(\n",
    "        description='Body Type:',\n",
    "        placeholder='Choose ''o'' for other or ''h'' for head...',\n",
    "        layout=widgets.Layout(width='500px'),\n",
    "        style={'description_width': '200px'}\n",
    "    )\n",
    "    model_path_input = widgets.Text(\n",
    "        description='Model File Path:',\n",
    "        placeholder='File Path Here...',\n",
    "        layout=widgets.Layout(width='500px'),\n",
    "        style={'description_width': '200px'}\n",
    "    )\n",
    "\n",
    "    # Variables\n",
    "    lr = lr_input.value\n",
    "    num_iters = iter_input.value\n",
    "    input_path = artifact_path_input.value\n",
    "    clean_path = clean_path_input.value\n",
    "    input_anatomy = anatomy_input.value\n",
    "\n",
    "    # Callback/Update Functions\n",
    "    def get_lr(change):\n",
    "        global lr\n",
    "        lr = change['new']\n",
    "        print(f\"Selected learning rate: {lr}\")\n",
    "\n",
    "    def get_num_iter(change):\n",
    "        global num_iters\n",
    "        num_iters = change['new']\n",
    "        print(f\"iteration number: {num_iters}\")\n",
    "\n",
    "    def get_input_path(change):\n",
    "        global input_path\n",
    "        input_path = change['new'].strip('\\\"\\'')\n",
    "        print(f\"File path entered: {input_path}\")\n",
    "\n",
    "    def get_clean_path(change):\n",
    "        global clean_path\n",
    "        clean_path = change['new'].strip('\\\"\\'')\n",
    "        print(f\"File path entered: {clean_path}\")\n",
    "    \n",
    "    def get_anatomy(change):\n",
    "        global input_anatomy\n",
    "        input_anatomy = change['new']\n",
    "        print(f\"File path entered: {input_anatomy}\")\n",
    "\n",
    "    def get_model_path(change):\n",
    "        global model_path\n",
    "        model_path = change['new'].strip('\\\"\\'')\n",
    "        print(f\"File path entered: {model_path}\")\n",
    "\n",
    "    # Events\n",
    "    lr_input.observe(get_lr, names='value')\n",
    "    iter_input.observe(get_num_iter, names='value')\n",
    "    artifact_path_input.observe(get_input_path, names='value')\n",
    "    clean_path_input.observe(get_clean_path, names='value')\n",
    "    anatomy_input.observe(get_anatomy, names= 'value')\n",
    "    model_path_input.observe(get_model_path, names='value')\n",
    "\n",
    "    # Display\n",
    "    display(lr_input, iter_input, artifact_path_input, clean_path_input, anatomy_input, model_path_input)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-wise Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Algorithm\n",
    "\n",
    "def iterative_descent(sample_name, input_scan, clean_image, input_anatomy, labels, discriminator, loss_fn, num_iters, device, optimizer= None, scheduler= None, lr= None, visualize_iter= False):\n",
    "    \"\"\"\n",
    "    Generic training loop for the gradientifier\n",
    "    \"\"\"\n",
    "\n",
    "    ### Iteration setup\n",
    "\n",
    "    # Stopping criteria # Tracking variables for stopping\n",
    "    total_iter = 0\n",
    "    tolerance = 5e-1\n",
    "    patience_count = 999999\n",
    "    previous_loss = float('inf')\n",
    "    no_improvement_count = 0\n",
    "    lowest_out = 9\n",
    "\n",
    "    # Loggings\n",
    "    network_output = []\n",
    "    loss_by_iter = []\n",
    "    ssd_by_iter = []\n",
    "    run_path = get_run()\n",
    "\n",
    "    write_log(run_path, [sample_name, num_iters, lr, 0])\n",
    "\n",
    "    # Load the classifier and freeze weights # Sort out labels for loss\n",
    "    classifier = discriminator.to(device)\n",
    "    classifier.eval()\n",
    "    label_class = torch.tensor([labels]).unsqueeze(1).float().to(device)\n",
    "\n",
    "    # Image view metal mask is here\n",
    "    classifier_threshold = 1999\n",
    "    iterative_threshold = np.max(input_scan) / 3\n",
    "    metal_mask = prepare_mask(input_scan, iterative_threshold)\n",
    "    masked_input = input_scan.copy()\n",
    "    masked_input[metal_mask] = -1001\n",
    "    masked_input[~metal_mask] = -1000\n",
    "    \n",
    "    # To sinogram view\n",
    "    with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "        input = projection(input_anatomy, input_scan)\n",
    "        metal_sino = projection(input_anatomy, masked_input)\n",
    "\n",
    "    m = metal_sino < 0\n",
    "    max = np.mean(metal_sino[m])\n",
    "    print(f\"Number of selection of mask: {np.sum(m)}; Starting max: {max}\")\n",
    "\n",
    "    ### Main iteration loop\n",
    "\n",
    "    for iteration in range(1, num_iters + 1):\n",
    "\n",
    "        # Echo to check differing indices this iteration\n",
    "        temp = input.copy()\n",
    "        figures, names = [], []\n",
    "        classifier.zero_grad()\n",
    "\n",
    "\n",
    "        ### Classifier and loss calculation\n",
    "\n",
    "        # Transform sino view to scan view\n",
    "        with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "            image = reconstruction(input_anatomy, input)\n",
    "\n",
    "        # Prepare and load scan view\n",
    "        raw = prepare_raw(image.copy(), classifier_threshold)\n",
    "        raw = raw.to(device)\n",
    "\n",
    "        # Get the outputs from the classifier\n",
    "        output = classifier(raw)\n",
    "        raw.retain_grad()\n",
    "\n",
    "        output.backward()\n",
    "\n",
    "        ssd_value = ssd(image, clean_image, 'scan')\n",
    "\n",
    "        print(f\"Iteration {iteration}  |  Output: {output.item()}  |  SSD: {ssd_value:.4f}\")\n",
    "\n",
    "\n",
    "        ### Handling gradients and transform into sinogram domain\n",
    "\n",
    "        # Get the scan view gradients\n",
    "        grads_image = raw.grad.data.detach().cpu().numpy().squeeze(0)\n",
    "        grads_image_orig = grads_image.copy()\n",
    "\n",
    "        # Transform into HU scale\n",
    "        grads_image = (grads_image * 1000) - 1000\n",
    "\n",
    "        # Use AAPMproj routine to transform to sinusoid view\n",
    "        with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "            grads_sino = projection(input_anatomy, grads_image)\n",
    "\n",
    "\n",
    "        ### Update the original input with gradients\n",
    "        input[m == 1] -= (grads_sino[m == 1] * lr)\n",
    "\n",
    "        grads_mask = grads_sino.copy()\n",
    "        grads_mask[m != 1] = 0\n",
    "\n",
    "\n",
    "        ### Terminating conditions and loggings\n",
    "\n",
    "        # Visualization at step: Input Image, Image Level Grad Map, Image View Metal Mask, Sinogram Metal Mask, Input Sinogram\n",
    "        if iteration % 5 == 0 or iteration == 1:\n",
    "            _ = (lambda x: figures.append(x[0]) or names.append(x[1]))(frame_iteration(image, grads_image_orig, masked_input, grads_mask, input, iteration, clean_image, output.item()))# loss.item()))\n",
    "\n",
    "        # Save current iteration output\n",
    "        with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "            scan_output = reconstruction(input_anatomy, input)\n",
    "\n",
    "        _ = (lambda x: figures.append(x[0]) or names.append(x[1]))(frame_scans(input_scan, scan_output, clean_image, iteration, output.item(), ssd_value))\n",
    "\n",
    "        # Save iteration files to disk\n",
    "        save_to_disk(run_path, figures, names)\n",
    "\n",
    "        # Check here changed number of indices\n",
    "        diff = temp != input\n",
    "        print(f\"Difference: {np.count_nonzero(diff)}\")\n",
    "\n",
    "        # Check stopping condition 1\n",
    "        # if output.item() <= -2:\n",
    "        #     print(f\"Early stopping at iteration {iteration} due to classification threshold breakpoint.\")\n",
    "        #     break\n",
    "\n",
    "        # Update stopping condition 1\n",
    "        # if abs(previous_loss - loss.item()) <= tolerance:\n",
    "        #     no_improvement_count += 1\n",
    "        # else:\n",
    "        #     no_improvement_count = 0\n",
    "\n",
    "        # Check stopping condition 1\n",
    "        if patience_count <= no_improvement_count:\n",
    "            print(f\"Early stopping at iteration {iteration} due to minimal improvement.\")\n",
    "            break\n",
    "\n",
    "        # Logging output and loss\n",
    "        network_output.append(output.item())\n",
    "        loss_by_iter.append(0) # loss.item())\n",
    "        ssd_by_iter.append(ssd_value)\n",
    "\n",
    "        total_iter = iteration\n",
    "\n",
    "        print(f\"======================================================================\")\n",
    "\n",
    "\n",
    "    ### Send to output and final viz\n",
    "\n",
    "    # Graph the logs\n",
    "    frame, name = frame_logging(network_output, loss_by_iter, ssd_by_iter, total_iter)\n",
    "\n",
    "    # Save end of run data\n",
    "    save_to_disk(run_path, [frame], [name])\n",
    "\n",
    "    # Convert changed sinosoid to raw for last time\n",
    "    with contextlib.redirect_stdout(open(os.devnull, 'w')):\n",
    "        scan_output = reconstruction(input_anatomy, input)\n",
    "\n",
    "    # Return the final image (input is sinogram output here)\n",
    "    return scan_output\n",
    "\n",
    "\n",
    "### Script\n",
    "\n",
    "def main_script(*args):\n",
    "    \"\"\"\n",
    "    Arguments\n",
    "    Arg 0 : Model filepath\n",
    "    Arg 1 : Input anatomy\n",
    "    Arg 2 : Input filepath\n",
    "    Arg 3 : Clean filepath\n",
    "    \"\"\"\n",
    "\n",
    "    ### User Vars\n",
    "\n",
    "    # Model variables # Training variables\n",
    "    num_classes = 1\n",
    "    label_class = 0\n",
    "    model_path = args[0]\n",
    "    num_iters = args[4]\n",
    "    lr = args[5]\n",
    "\n",
    "    # Set raw path input\n",
    "    input_anatomy = args[1]\n",
    "    input_path = args[2]\n",
    "    clean_path = args[3]\n",
    "    sample_name = '_'.join(input_path.split('_')[4:5])\n",
    "\n",
    "    # Load images and normalize entry of inputs, reshape\n",
    "    input_scan = np.fromfile(input_path, dtype='float32', sep=\"\").reshape([1, 512, 512])\n",
    "    clean_image = np.fromfile(clean_path, dtype='float32', sep=\"\").reshape([1, 512, 512])\n",
    "    \n",
    "    # Load classifier # Load loss function, optimizer, and scheduler for gradient # Define device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    classifier = Tiny_Classifier_A(num_classes)\n",
    "    classifier.load_state_dict(torch.load(model_path, map_location=torch.device(device)))\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "    ### Main routine\n",
    "\n",
    "    # Start loop and get output\n",
    "    scan_output = iterative_descent(sample_name, input_scan, clean_image, input_anatomy, label_class, classifier, loss_fn, num_iters, device, lr= lr, visualize_iter= True)\n",
    "\n",
    "\n",
    "    ### Cleanup and Analyzation\n",
    "\n",
    "    # Clean the environment\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main_script(model_path, input_anatomy, input_path, clean_path, num_iters, lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI-ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
